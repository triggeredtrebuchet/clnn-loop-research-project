{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3be143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data = json.load(open(\"data/project_data/dev.json\"))\n",
    "right_x = [data[i][0] for i in data]\n",
    "left_x = [data[i][1] for i in data]\n",
    "y = [data[i][2] for i in data]\n",
    "\n",
    "# write right_x as a .fasta file\n",
    "with open(\"data/project_data/dev_right.fasta\", \"w\") as f:\n",
    "    for i in right_x:\n",
    "        f.write(\">+\\n\")\n",
    "        f.write(i)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# write left_x as a .fasta file\n",
    "with open(\"data/project_data/dev_left.fasta\", \"w\") as f:\n",
    "    for i in left_x:\n",
    "        f.write(\">-\\n\")\n",
    "        f.write(i)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "np.save('data/project_data/dev_y.npy', np.array(y))\n",
    "\n",
    "data = json.load(open(\"data/project_data/train.json\"))\n",
    "right_x = [data[i][0] for i in data]\n",
    "left_x = [data[i][1] for i in data]\n",
    "y = [data[i][2] for i in data]\n",
    "\n",
    "# write right_x as a .fasta file\n",
    "with open(\"data/project_data/train_right.fasta\", \"w\") as f:\n",
    "    for i in right_x:\n",
    "        f.write(\">+\\n\")\n",
    "        f.write(i)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# write left_x as a .fasta file\n",
    "with open(\"data/project_data/train_left.fasta\", \"w\") as f:\n",
    "    for i in left_x:\n",
    "        f.write(\">-\\n\")\n",
    "        f.write(i)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "np.save('data/project_data/train_y.npy', np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6269f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_code\n",
    "feature_code.create_features(output_train = 'project_train.npy', output_dev = 'project_dev.npy', cell_line = 'project_data/', dev_left = 'data/project_data/dev_left', dev_right = 'data/project_data/dev_right',\n",
    "                    train_left = 'data/project_data/train_left', train_right = 'data/project_data/train_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10031511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1208, 32)          512       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 604, 32)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 604, 32)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 590, 32)           15392     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 295, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 295, 32)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 281, 32)           15392     \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 281, 128)          49664     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 35968)             0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 35968)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 35969     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116929 (456.75 KB)\n",
      "Trainable params: 116929 (456.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "WARNING:tensorflow:From C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.6574 - accuracy: 0.5962\n",
      "Epoch 1: val_loss improved from inf to 0.68357, saving model to best_two_CNN_LSTM.hdf5\n",
      "100/100 [==============================] - 41s 325ms/step - loss: 0.6574 - accuracy: 0.5962 - val_loss: 0.6836 - val_accuracy: 0.5850\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.6740\n",
      "Epoch 2: val_loss improved from 0.68357 to 0.60478, saving model to best_two_CNN_LSTM.hdf5\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.6045 - accuracy: 0.6740 - val_loss: 0.6048 - val_accuracy: 0.6520\n",
      "Epoch 3/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.7086\n",
      "Epoch 3: val_loss improved from 0.60478 to 0.58032, saving model to best_two_CNN_LSTM.hdf5\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.5669 - accuracy: 0.7086 - val_loss: 0.5803 - val_accuracy: 0.6930\n",
      "Epoch 4/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7140\n",
      "Epoch 4: val_loss improved from 0.58032 to 0.57053, saving model to best_two_CNN_LSTM.hdf5\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.5616 - accuracy: 0.7140 - val_loss: 0.5705 - val_accuracy: 0.6890\n",
      "Epoch 5/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.7150\n",
      "Epoch 5: val_loss improved from 0.57053 to 0.56486, saving model to best_two_CNN_LSTM.hdf5\n",
      "100/100 [==============================] - 33s 328ms/step - loss: 0.5549 - accuracy: 0.7150 - val_loss: 0.5649 - val_accuracy: 0.7110\n",
      "Epoch 6/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.7234\n",
      "Epoch 6: val_loss improved from 0.56486 to 0.56247, saving model to best_two_CNN_LSTM.hdf5\n",
      "100/100 [==============================] - 40s 397ms/step - loss: 0.5513 - accuracy: 0.7234 - val_loss: 0.5625 - val_accuracy: 0.7090\n",
      "Epoch 7/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.7202\n",
      "Epoch 7: val_loss did not improve from 0.56247\n",
      "100/100 [==============================] - 35s 346ms/step - loss: 0.5520 - accuracy: 0.7202 - val_loss: 0.5689 - val_accuracy: 0.7160\n",
      "Epoch 8/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.7222\n",
      "Epoch 8: val_loss did not improve from 0.56247\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.5519 - accuracy: 0.7222 - val_loss: 0.5752 - val_accuracy: 0.7020\n",
      "Epoch 9/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5461 - accuracy: 0.7276\n",
      "Epoch 9: val_loss did not improve from 0.56247\n",
      "100/100 [==============================] - 33s 333ms/step - loss: 0.5461 - accuracy: 0.7276 - val_loss: 0.5707 - val_accuracy: 0.6940\n",
      "Epoch 10/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.7246\n",
      "Epoch 10: val_loss improved from 0.56247 to 0.56019, saving model to best_two_CNN_LSTM.hdf5\n",
      "100/100 [==============================] - 33s 328ms/step - loss: 0.5478 - accuracy: 0.7246 - val_loss: 0.5602 - val_accuracy: 0.7020\n",
      "Epoch 11/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5497 - accuracy: 0.7206\n",
      "Epoch 11: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.5497 - accuracy: 0.7206 - val_loss: 0.5695 - val_accuracy: 0.7020\n",
      "Epoch 12/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.7224\n",
      "Epoch 12: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 0.5479 - accuracy: 0.7224 - val_loss: 0.5675 - val_accuracy: 0.7120\n",
      "Epoch 13/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.7290\n",
      "Epoch 13: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 0.5482 - accuracy: 0.7290 - val_loss: 0.5647 - val_accuracy: 0.7010\n",
      "Epoch 14/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.7272\n",
      "Epoch 14: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 34s 337ms/step - loss: 0.5439 - accuracy: 0.7272 - val_loss: 0.5643 - val_accuracy: 0.7010\n",
      "Epoch 15/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.7176\n",
      "Epoch 15: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 0.5486 - accuracy: 0.7176 - val_loss: 0.5663 - val_accuracy: 0.7050\n",
      "Epoch 16/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7268\n",
      "Epoch 16: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 33s 333ms/step - loss: 0.5446 - accuracy: 0.7268 - val_loss: 0.5686 - val_accuracy: 0.7040\n",
      "Epoch 17/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.7278\n",
      "Epoch 17: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 0.5439 - accuracy: 0.7278 - val_loss: 0.5677 - val_accuracy: 0.6910\n",
      "Epoch 18/300\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.7308\n",
      "Epoch 18: val_loss did not improve from 0.56019\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 0.5472 - accuracy: 0.7308 - val_loss: 0.5661 - val_accuracy: 0.7070\n",
      "train\n",
      "157/157 [==============================] - 9s 53ms/step\n",
      "157/157 [==============================] - 9s 55ms/step\n",
      "auc,acc,mcc,precision,recall,fscore,support: 0.8047142788561553 0.494 0.0 0.247 0.5 0.33065595716198126 None\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 982ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "auc,acc,mcc,precision,recall,fscore,support: 0.7083333333333333 0.6 0.0 0.3 0.5 0.37499999999999994 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trebuh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import LSTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import data_load\n",
    "\n",
    "x_dev = np.load('project_dev.npy')\n",
    "y_dev = np.load('data/project_data/dev_y.npy')\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=10)\n",
    "\n",
    "x_train = np.load('project_train.npy')\n",
    "y_train = np.load('data/project_data/train_y.npy')\n",
    "\n",
    "# x_test = np.load('K562_RR_test.npy')\n",
    "# print(x_test.shape)\n",
    "# y1 = np.ones(int(len(x_test)/2))\n",
    "# y2 = np.zeros(int(len(x_test)/2))\n",
    "# y_test = np.concatenate((y1,y2),axis=0)\n",
    "# print(y_test.shape)\n",
    "\n",
    "\n",
    "INPUT_SHAPE = x_train.shape[1:3]\n",
    "'''KERNEL_SIZE = 5\n",
    "LEARNING_RATE = 0.001\n",
    "LSTM_UNITS = 32'''\n",
    "\n",
    "LEARNING_RATE = 0.00075\n",
    "KERNEL_NUMBER = 32\n",
    "KERNEL_SIZE = 15\n",
    "LSTM_UNITS = 64\n",
    "\n",
    "# kernel_numbers = [32, 64, 128]\n",
    "# kernel_sizes = [5, 10, 15, 20]\n",
    "#\n",
    "# for kernel_number in kernel_numbers:\n",
    "#     for kernel_size in kernel_sizes:\n",
    "#         print(kernel_number, kernel_size)\n",
    "#         LSTM.three_CNN_LSTM1(x_train, y_train, x_dev, y_dev,\n",
    "#                             x_dev[:10], y_dev[:10], LEARNING_RATE, INPUT_SHAPE, kernel_number, kernel_size, LSTM_UNITS,\n",
    "#                              name = \"three_CNN_LSTM1_{}_{}\".format(kernel_number, kernel_size))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tuning, model = LSTM.three_CNN_LSTM1(x_train, y_train, x_dev, y_dev,\n",
    "                    x_dev[:10], y_dev[:10], LEARNING_RATE, INPUT_SHAPE, KERNEL_NUMBER, KERNEL_SIZE, LSTM_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56beba99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    }
   ],
   "source": [
    "# predict sample sequence\n",
    "prediction = model.predict(x_dev[:20]).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55fa14aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49034965, 0.        ],\n",
       "       [0.10361491, 0.        ],\n",
       "       [0.87257653, 0.        ],\n",
       "       [0.71764135, 1.        ],\n",
       "       [0.94688398, 1.        ],\n",
       "       [0.26773211, 0.        ],\n",
       "       [0.83491367, 0.        ],\n",
       "       [0.18540558, 1.        ],\n",
       "       [0.9464162 , 1.        ],\n",
       "       [0.30621985, 0.        ],\n",
       "       [0.52775478, 1.        ],\n",
       "       [0.11365655, 0.        ],\n",
       "       [0.61302471, 1.        ],\n",
       "       [0.34458894, 0.        ],\n",
       "       [0.94568324, 0.        ],\n",
       "       [0.24346417, 0.        ],\n",
       "       [0.48716009, 0.        ],\n",
       "       [0.9829222 , 1.        ],\n",
       "       [0.41535348, 0.        ],\n",
       "       [0.85719979, 1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([prediction, y_dev[:20]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40906c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
